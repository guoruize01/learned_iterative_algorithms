MC = 1000               # MC is the number of transmitted messages (Monte Carlo simulations)
L = 32                  # L is the number of sections
bps = 4                 # bits per section
R = 1.0                 # R is the rate of the code, bits per channel use
n = int(L*bps/R)        # number of channel uses, i.e., number of rows of A
SNR_dB = 8              # training and evaluation SNR in dB

# Create the basic problem structure.
prob = problems.ssc_problem(n=n, L=L, bps=bps, MC=MC, SNR_dB=SNR_dB)


# # build a LAMP network to solve the problem and get the intermediate results so we can greedily extend and then refine(fine-tune)
layers = networks.build_LAMP4SSC(prob,T=8,untied=True)
print('Building layers ... done')


# plan the learning
# training_stages = train.setup_LAMP4SSCtraining(layers,prob,trinit=1e-3, refinements=(.5,) )
training_stages = train.setup_LAMP4SSCtraining(layers,prob,trinit=1e-3,refinements=(.5,.1,.01) )
print('Plan the learning ... done')

# do the learning (takes a whixle)
print('Do the learning (takes a while)')
# sess = train.do_LAMP4SSCtraining(training_stages,prob,'LAMP4SSC.npz',10,10,10)
sess = train.do_LAMP4SSCtraining(training_stages,prob,'LAMP4SSC.npz',10,10000,500)
# sess = train.do_LAMP4SSCtraining(training_stages,prob,'LAMP4SSC.npz')

# train.plot_estimate_to_test_message(sess, training_stages, prob, 'LAMP_bg_giid.npz' )
# train.test_vector_sizes(sess, training_stages, prob, 'LAMP_bg_giid.npz' )
train.evaluate_LAMP4SSC_nmse(sess, training_stages, prob, 'LAMP4SSC.npz' )

train_vars = train.get_train_variables(sess)



################################################################################
################################################################################

def build_LAMP4SSC(prob,T,untied):
    L = prob.L

    theta_init = 1.
    print('theta_init=' + repr(theta_init))
    theta_ = tf.Variable(theta_init, dtype=tf.float32, name='theta_0')

    layers = []
    A = prob.A
    A_ = prob.A_
    n, N = A.shape
    B = A.T
    B_ = tf.Variable(B, dtype=tf.float32, name='B_0')
    z_ = prob.y_

    s_ = tf.matmul(B_, z_)

    layers.append(('LAMP for SSC Linear-B\t', s_, None))

    tau_ = theta_ * tf.sqrt(tf.reduce_sum(z_ ** 2, axis=0) / n)
    s1_ = prob.sqrtnPl * tf.matmul((s_ - prob.sqrtnPl), tf.linalg.diag(1 / (tau_ ** 2)))
    s2_ = tf.reshape(tf.transpose(s1_), (-1, prob.B))
    beta_rs_ = prob.sqrtnPl * tf.nn.softmax(s2_, axis=1)

    beta_ = tf.transpose(tf.reshape(beta_rs_, [-1, N]))

    layers.append( ('LAMP for SSC non-linear T=1\t', beta_, (theta_,)) )

   	for t in range(1,T):
        ons_ = tf.matmul( z_, tf.linalg.diag(1 / (tau_ ** 2)))
        ons_ = tf.matmul( ons_, tf.linalg.diag(prob.P - tf.norm(beta_, axis=0)**2/n))
        z_ = prob.y_ - tf.matmul(A_, beta_) + ons_
        # z_ = prob.y_ - tf.matmul(A_, beta_)

        if untied:
            B_ =  tf.Variable(B,dtype=tf.float32,name='B_'+str(t))
            s_ = beta_ + tf.matmul(B_, z_)
            layers.append( ('LAMP for SSC linear-B T={0}'.format(t+1),s_ ,(B_,) ) )
        else:
            s_ = beta_ + tf.matmul(B_, z_)


        theta_ = tf.Variable(theta_init, name='theta_' + str(t))
        tau_ = theta_ * tf.sqrt(tf.reduce_sum(z_ ** 2, axis=0) / n)

        s1_ = prob.sqrtnPl * tf.matmul((s_ - prob.sqrtnPl), tf.linalg.diag(1 / (tau_ ** 2)))
        s2_ = tf.reshape(tf.transpose(s1_), (-1, prob.B))
        beta_rs_ = prob.sqrtnPl * tf.nn.softmax(s2_, axis=1)

        beta_ = tf.transpose(tf.reshape(beta_rs_, [-1, N]))

        layers.append(('LAMP for SSC non-linear T={0}\t'.format(t + 1), beta_, (theta_,)))